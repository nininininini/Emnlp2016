SubmissionNumber#=%=#677
FinalPaperTitle#=%=#There's No Comparison: Reference-less Evaluation Metrics in Grammatical Error Correction
ShortPaperTitle#=%=#There's No Comparison: Reference-less Evaluation Metrics in Grammatical Error Correction
NumberOfPages#=%=#7
CopyrightSigned#=%=#CN
JobTitle#==#
Organization#==#
Abstract#==#Current methods for automatically evaluating grammatical error correction (GEC)
systems rely on gold-standard references. However, these methods suffer from
penalizing grammatical edits that are correct but not in the gold standard. We
show that reference-less grammaticality metrics correlate very strongly with
human judgments and are competitive with the leading reference-based evaluation
metrics. By interpolating both methods, we achieve state-of-the-art correlation
with human judgments. Finally, we show that GEC metrics are much more reliable
when they are calculated at the sentence level instead of the corpus level. We
have set up a CodaLab site for benchmarking GEC output using a common dataset
and different evaluation metrics.
Author{1}{Firstname}#=%=#Courtney
Author{1}{Lastname}#=%=#Napoles
Author{1}{Email}#=%=#cdnapoles@gmail.com
Author{1}{Affiliation}#=%=#Johns Hopkins University
Author{2}{Firstname}#=%=#Keisuke
Author{2}{Lastname}#=%=#Sakaguchi
Author{2}{Email}#=%=#keisuke@cs.jhu.edu
Author{2}{Affiliation}#=%=#Johns Hopkins University
Author{3}{Firstname}#=%=#Joel
Author{3}{Lastname}#=%=#Tetreault
Author{3}{Email}#=%=#tetreaul@gmail.com
Author{3}{Affiliation}#=%=#Grammarly

==========