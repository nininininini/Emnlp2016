SubmissionNumber#=%=#53
FinalPaperTitle#=%=#Comparing Data Sources and Architectures for Deep Visual Representation Learning in Semantics
ShortPaperTitle#=%=#Comparing Data Sources and Architectures for Deep Visual Representation Learning in Semantics
NumberOfPages#=%=#10
CopyrightSigned#=%=#Douwe Kiela
JobTitle#==#
Organization#==#
Abstract#==#Multi-modal distributional models learn grounded representations for improved
performance in semantics tasks. Deep visual representations, learned using
convolutional neural networks, have been shown to achieve particularly high
performance. In this study, we systematically compare deep visual
representation learning techniques, experimenting with three well-known network
architectures. In addition, we explore the various data sources that can be
used for retrieving relevant images, showing that images from search engines
perform as well as, or better than, manually crafted resources such as
ImageNet. Furthermore, we explore the optimal number of images and the
multi-lingual applicability of multi-modal semantics. We hope that these
findings can serve as a guide for future research in the field.
Author{1}{Firstname}#=%=#Douwe
Author{1}{Lastname}#=%=#Kiela
Author{1}{Email}#=%=#douwe.kiela@cl.cam.ac.uk
Author{1}{Affiliation}#=%=#University of Cambridge Computer Laboratory
Author{2}{Firstname}#=%=#Anita Lilla
Author{2}{Lastname}#=%=#Ver≈ë
Author{2}{Email}#=%=#alv34@cam.ac.uk
Author{2}{Affiliation}#=%=#University of Cambridge
Author{3}{Firstname}#=%=#Stephen
Author{3}{Lastname}#=%=#Clark
Author{3}{Email}#=%=#sc609@cam.ac.uk
Author{3}{Affiliation}#=%=#University of Cambridge

==========