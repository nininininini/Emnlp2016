SubmissionNumber#=%=#903
FinalPaperTitle#=%=#SQuAD: 100,000+ Questions for Machine Comprehension of Text
ShortPaperTitle#=%=#SQuAD: 100,000+ Questions for Machine Comprehension of Text
NumberOfPages#=%=#10
CopyrightSigned#=%=#Pranav Rajpurkar
JobTitle#==#
Organization#==#Stanford University
353 Serra Mall, Stanford, CA, USA
Abstract#==#We present the Stanford Question Answering Dataset (SQuAD), a new reading
comprehension dataset consisting of 100,000+ questions posed by crowdworkers on
a set of Wikipedia articles, where the answer to each question is a segment of
text from the corresponding reading passage. We analyze the dataset to
understand the types of reasoning required to answer the questions, leaning
heavily on dependency and constituency trees. We build a strong logistic
regression model, which achieves an F1 score of 51.0%, a significant
improvement over a simple baseline (20%). However, human performance (86.8%) is
much higher, indicating that the dataset presents a good challenge problem for
future research.

The dataset is freely available at https://stanford-qa.com.
Author{1}{Firstname}#=%=#Pranav
Author{1}{Lastname}#=%=#Rajpurkar
Author{1}{Email}#=%=#pranavsr@cs.stanford.edu
Author{1}{Affiliation}#=%=#Stanford University
Author{2}{Firstname}#=%=#Jian
Author{2}{Lastname}#=%=#Zhang
Author{2}{Email}#=%=#zjian@cs.stanford.edu
Author{2}{Affiliation}#=%=#Stanford University
Author{3}{Firstname}#=%=#Konstantin
Author{3}{Lastname}#=%=#Lopyrev
Author{3}{Email}#=%=#klopyrev@cs.stanford.edu
Author{3}{Affiliation}#=%=#Stanford University
Author{4}{Firstname}#=%=#Percy
Author{4}{Lastname}#=%=#Liang
Author{4}{Email}#=%=#pliang@cs.stanford.edu
Author{4}{Affiliation}#=%=#Stanford University

==========