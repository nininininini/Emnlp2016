SubmissionNumber#=%=#1060
FinalPaperTitle#=%=#Context-Dependent Sense Embedding
ShortPaperTitle#=%=#Context-Dependent Sense Embedding
NumberOfPages#=%=#9
CopyrightSigned#=%=#Lin Qiu
JobTitle#==#Student
Organization#==#Shanghai Jiao Tong University
Abstract#==#Word embedding has been widely studied and proven helpful in solving many
natural language processing tasks. However, the ambiguity of natural language
is always a problem on learning high quality word embeddings. A possible
solution is sense embedding which trains embedding for each sense of words
instead of each word. Some recent work on sense embedding uses context
clustering methods to determine the senses of words, which is heuristic in
nature. Other work creates a probabilistic model and performs word sense
disambiguation and sense embedding iteratively. However, most of the previous
work has the problems of learning sense embeddings based on imperfect word
embeddings as well as ignoring the dependency between sense choices of
neighboring words. In this paper, we propose a novel probabilistic model for
sense embedding that is not based on problematic word embedding of polysemous
words and takes into account the dependency between sense choices. Based on our
model, we derive a dynamic programming inference algorithm and an
Expectation-Maximization style learning algorithm. The empirical studies show
that our model outperforms the state-of-the-art model on a word sense induction
task by a 13% relative gain.
Author{1}{Firstname}#=%=#Lin
Author{1}{Lastname}#=%=#Qiu
Author{1}{Email}#=%=#lqiu@apex.sjtu.edu.cn
Author{1}{Affiliation}#=%=#Shanghai Jiao Tong University
Author{2}{Firstname}#=%=#Kewei
Author{2}{Lastname}#=%=#Tu
Author{2}{Email}#=%=#tukw@shanghaitech.edu.cn
Author{2}{Affiliation}#=%=#ShanghaiTech University
Author{3}{Firstname}#=%=#Yong
Author{3}{Lastname}#=%=#Yu
Author{3}{Email}#=%=#yyu@apex.sjtu.edu.cn
Author{3}{Affiliation}#=%=#Shanghai Jiao Tong University

==========