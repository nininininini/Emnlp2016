1   # The Galactic Dependencies Treebanks: Getting More Data by Synthesizing New Languages
2   # Minimally supervised models for number normalization
3   # Sparse Non-negative Matrix Language Modeling
4   # Easy-First Dependency Parsing with Hierarchical Tree LSTMs
5   # Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation
6   # Fast, Small and Exact: Infinite-order Language Modelling with Compressed Suffix Trees
7   # Understanding Satirical Articles Using Common-Sense
8   # Large-scale Analysis of Counseling Conversations: An Application of Natural Language Processing to Mental Health
9   # Comparing Apples to Apple: The Effects of Stemmers on Topic Models
