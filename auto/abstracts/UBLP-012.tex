In this paper, we present the concept of using language groundings for context-sensitive text prediction using a semantically informed, context-aware language model. We show initial findings from a preliminary study investigating how users react to a communication interface driven by context based prediction using a simple language model. We suggest that the results support further exploration using a more informed semantic model and more realistic context.
